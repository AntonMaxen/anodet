{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import wide_resnet50_2, resnet18\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from padim_utils import AnomalyDetector, extractEmbeddingVectors, getParameters, extractEmbeddingVectorsBatched\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets.mvtec as mvtec\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "from sklearn.covariance import LedoitWolf\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from random import sample\n",
    "\n",
    "from feature_extraction import Resnet18Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = 'bottle'\n",
    "data_path = '../mvtec_dataset/'\n",
    "dataset = mvtec.MVTecDataset(data_path, class_name=class_name, is_train=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, pin_memory=True)\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, mask = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet18(pretrained=True, progress=True)\n",
    "# model = wide_resnet50_2(pretrained=True, progress=True)\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.917397912000002\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "outputs = []\n",
    "\n",
    "def hook(module, input, output):\n",
    "    outputs.append(output)\n",
    "\n",
    "model.layer1[-1].register_forward_hook(hook)\n",
    "model.layer2[-1].register_forward_hook(hook)\n",
    "model.layer3[-1].register_forward_hook(hook)    \n",
    "#     model.layer4[-1].register_forward_hook(hook)    \n",
    "\n",
    "train_outputs = OrderedDict([('layer1', []), ('layer2', []), ('layer3', [])])\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = model(x.to(device))\n",
    "# get intermediate layer outputs\n",
    "for k, v in zip(train_outputs.keys(), outputs):\n",
    "    train_outputs[k].append(v.cpu().detach())\n",
    "\n",
    "# initialize hook outputs\n",
    "outputs = []\n",
    "\n",
    "for k, v in train_outputs.items():\n",
    "    train_outputs[k] = torch.cat(v, 0)\n",
    "\n",
    "    \n",
    "    \n",
    "embedding_vectors = expandFeatures([train_outputs['layer1'], train_outputs['layer2'], train_outputs['layer3']])\n",
    "\n",
    "print(time.perf_counter()-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 56, 56])\n",
      "tensor([0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0602, 0.1600, 0.2776, 0.3511, 0.3092,\n",
      "        0.2175, 0.1496, 0.1211, 0.4365, 0.4459, 0.4752, 0.5137, 0.5318, 0.5286,\n",
      "        0.5006, 0.4708, 0.4541, 0.4969, 0.5557, 0.5626, 0.4758, 0.2799, 0.1860,\n",
      "        0.0000, 0.1041, 0.3207, 0.3926, 0.5066, 0.3453, 0.0675, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0186,\n",
      "        0.2225, 0.2169])\n"
     ]
    }
   ],
   "source": [
    "print(embedding_vectors.shape)\n",
    "print(embedding_vectors[0][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_features = Resnet18Features(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.372056385999997\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "with torch.no_grad():\n",
    "    features = resnet18_features(x)\n",
    "print(time.perf_counter()-tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(features))\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 448, 56, 56])\n",
      "tensor([0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0602, 0.1600, 0.2776, 0.3511, 0.3092,\n",
      "        0.2175, 0.1496, 0.1211, 0.4365, 0.4459, 0.4752, 0.5137, 0.5318, 0.5286,\n",
      "        0.5006, 0.4708, 0.4541, 0.4969, 0.5557, 0.5626, 0.4758, 0.2799, 0.1860,\n",
      "        0.0000, 0.1041, 0.3207, 0.3926, 0.5066, 0.3453, 0.0675, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0186,\n",
      "        0.2225, 0.2169])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(features[0][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 56, 56])\n",
      "tensor([[0.0080, 0.0000, 0.0000,  ..., 0.0186, 0.2225, 0.2169],\n",
      "        [0.3165, 0.4252, 0.3331,  ..., 0.4363, 0.6555, 0.5827],\n",
      "        [0.0690, 0.1611, 0.0030,  ..., 0.0766, 0.3925, 0.4344],\n",
      "        ...,\n",
      "        [0.2314, 0.3079, 0.1707,  ..., 0.2362, 0.3392, 0.3081],\n",
      "        [0.4463, 0.5012, 0.3271,  ..., 0.3008, 0.4765, 0.3464],\n",
      "        [0.2140, 0.3058, 0.2108,  ..., 0.1384, 0.3433, 0.3809]])\n"
     ]
    }
   ],
   "source": [
    "# Embedding concat\n",
    "embedding_vectors = expandFeatures([train_outputs['layer1'], train_outputs['layer2'], train_outputs['layer3']])\n",
    "\n",
    "# idx = getSeedIndices(100, 448, device)  \n",
    "# embedding_vectors = torch.index_select(embedding_vectors, 1, idx)\n",
    "print(embedding_vectors.shape)\n",
    "print(embedding_vectors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15946829599988632\n",
      "tensor([0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0602, 0.1600, 0.2776, 0.3511, 0.3092,\n",
      "        0.2175, 0.1496, 0.1211, 0.4365, 0.4459, 0.4752, 0.5137, 0.5318, 0.5286,\n",
      "        0.5006, 0.4708, 0.4541, 0.4969, 0.5557, 0.5626, 0.4758, 0.2799, 0.1860,\n",
      "        0.0000, 0.1041, 0.3207, 0.3926, 0.5066, 0.3453, 0.0675, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0186,\n",
      "        0.2225, 0.2169])\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "ef = expandFeatures2([train_outputs['layer1'], train_outputs['layer2'], train_outputs['layer3']])\n",
    "print(time.perf_counter()-tic)\n",
    "print(ef[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.547424023000076\n",
      "tensor([0.0080, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0602, 0.1600, 0.2776, 0.3511, 0.3092,\n",
      "        0.2175, 0.1496, 0.1211, 0.4365, 0.4459, 0.4752, 0.5137, 0.5318, 0.5286,\n",
      "        0.5006, 0.4708, 0.4541, 0.4969, 0.5557, 0.5626, 0.4758, 0.2799, 0.1860,\n",
      "        0.0000, 0.1041, 0.3207, 0.3926, 0.5066, 0.3453, 0.0675, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0186,\n",
      "        0.2225, 0.2169])\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "ef = expandFeatures([train_outputs['layer1'], train_outputs['layer2'], train_outputs['layer3']])\n",
    "print(time.perf_counter()-tic)\n",
    "print(ef[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandFeatures2(features):\n",
    "    \n",
    "    tot_depth = sum(feature.shape[1] for feature in features)\n",
    "    \n",
    "    concatenated_features = torch.zeros((features[0].shape[0], tot_depth, features[0].shape[2], features[0].shape[3]))\n",
    "    concatenated_features[:, 0:features[0].shape[1], :, :] = features[0]\n",
    "\n",
    "    last_depth = features[0].shape[0]\n",
    "    \n",
    "    for feature in features[1:]:\n",
    "        scale_factor = features[0].shape[3]/feature.shape[3]\n",
    "        upsampled_feature = torch.nn.Upsample(scale_factor=scale_factor, mode='nearest')(feature)\n",
    "        concatenated_features[:,last_depth:last_depth+upsampled_feature.shape[1], :, :] = upsampled_feature\n",
    "        last_depth += upsampled_feature.shape[1]\n",
    "\n",
    "    return concatenated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 56, 56])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
    "m(train_outputs['layer2']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEmbeddingVectorsBatched(x, model, device):\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        outputs.append(output)\n",
    "\n",
    "    model.layer1[-1].register_forward_hook(hook)\n",
    "    model.layer2[-1].register_forward_hook(hook)\n",
    "    model.layer3[-1].register_forward_hook(hook)    \n",
    "#     model.layer4[-1].register_forward_hook(hook)    \n",
    "\n",
    "    train_outputs = OrderedDict([('layer1', []), ('layer2', []), ('layer3', [])])\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _ = model(x.to(device))\n",
    "    # get intermediate layer outputs\n",
    "    for k, v in zip(train_outputs.keys(), outputs):\n",
    "        train_outputs[k].append(v.cpu().detach())\n",
    "\n",
    "    # initialize hook outputs\n",
    "    outputs = []\n",
    "        \n",
    "    for k, v in train_outputs.items():\n",
    "        train_outputs[k] = torch.cat(v, 0)\n",
    "\n",
    "\n",
    "    # Embedding concat\n",
    "    embedding_vectors = expandFeatures([train_outputs['layer1'], train_outputs['layer2'], train_outputs['layer3']])\n",
    "        \n",
    "    idx = getSeedIndices(100, 448, device)  \n",
    "    embedding_vectors = torch.index_select(embedding_vectors, 1, idx)\n",
    "    \n",
    "    return embedding_vectors\n",
    "\n",
    "\n",
    "# Expects the largest dimension first\n",
    "def expandFeatures(features):\n",
    "    expanded_features = features[0]\n",
    "    for feature in features:\n",
    "        expanded_features = embedding_concat(expanded_features, feature)\n",
    "    return expanded_features\n",
    "    \n",
    "\n",
    "\n",
    "def embedding_concat(x, y):\n",
    "    B, C1, H1, W1 = x.size()\n",
    "    _, C2, H2, W2 = y.size()\n",
    "    s = int(H1 / H2)\n",
    "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
    "    x = x.view(B, C1, -1, H2, W2)\n",
    "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2)\n",
    "    for i in range(x.size(2)):\n",
    "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
    "    del x\n",
    "    del y\n",
    "    z = z.view(B, -1, H2 * W2)\n",
    "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
    "    return z\n",
    "\n",
    "\n",
    "def getSeedIndices(choose, total, device):\n",
    "    random.seed(1024)\n",
    "    torch.manual_seed(1024)\n",
    "        \n",
    "    if device.type=='cuda':\n",
    "        torch.cuda.manual_seed_all(1024)\n",
    "    return torch.tensor(sample(range(0, total), choose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = extractEmbeddingVectorsBatched(x, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 56, 56])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParameters(embedding_vectors):\n",
    "    B, C, H, W = embedding_vectors.size()\n",
    "    embedding_vectors = embedding_vectors.view(B, C, H * W)\n",
    "    mean = torch.mean(embedding_vectors, dim=0).numpy()\n",
    "    cov = torch.zeros(C, C, H * W).numpy()\n",
    "    I = np.identity(C)\n",
    "\n",
    "    # embedding_vectors = torch.from_numpy(embedding_vectors)\n",
    "\n",
    "    for i in range(H * W):\n",
    "#         cov[:, :, i] = LedoitWolf().fit(embedding_vectors[:, :, i].numpy()).covariance_\n",
    "        cov[:, :, i] = np.cov(embedding_vectors[:, :, i].numpy(), rowvar=False) + 0.01 * I\n",
    "        \n",
    "    return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMeanAndCovarianceMatrix(embedding_vectors):\n",
    "    \n",
    "    B, C, H, W = embedding_vectors.size()\n",
    "    print(embedding_vectors.shape)\n",
    "    \n",
    "#     embedding_vectors = embedding_vectors.permute(1, 0, 2, 3)\n",
    "#     print(embedding_vectors.shape)\n",
    "        \n",
    "#     embedding_vectors = embedding_vectors.reshape(C, B * H * W)\n",
    "#     print(embedding_vectors.shape)\n",
    "    \n",
    "    embedding_vectors = embedding_vectors.view(B, C, H*W)\n",
    "    print('ev', embedding_vectors.shape)\n",
    "    \n",
    "    \n",
    "    mean = torch.mean(embedding_vectors, dim=0)\n",
    "    print('mean', mean.shape)\n",
    "    \n",
    "    \n",
    "    mean_expanded = mean.expand(B, C, H*W)\n",
    "    print('mean', mean_expanded.shape)\n",
    "\n",
    "    \n",
    "    diff = mean - embedding_vectors\n",
    "    print('diff:', diff.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    diff = diff.permute(0,2,1)\n",
    "    print('diff:', diff.shape)\n",
    "    \n",
    "#     diff = diff.reshape(B*H*W, C)\n",
    "#     print('diff:', diff.shape)\n",
    "    \n",
    "    \n",
    "#     diff = diff.unsqueeze(3)\n",
    "#     print('diff:', diff.shape)\n",
    "    \n",
    "#     diff_transpose = torch.transpose(diff, 2, 3)\n",
    "#     print('diff_transpose:', diff_transpose.shape)\n",
    "\n",
    "    diff_transpose = torch.transpose(diff, 1, 2)\n",
    "    print('diff_transpose:', diff_transpose.shape)\n",
    "    \n",
    "    \n",
    "    mult = torch.bmm(diff, diff_transpose)\n",
    "    \n",
    "    \n",
    "#     concat_mult = None\n",
    "#     for i in range(B):\n",
    "#         print(i)\n",
    "# #         print(diff[i].shape)\n",
    "# #         print(diff_transpose[i].shape)\n",
    "#         mult = torch.bmm(diff[i], diff_transpose[i])\n",
    "#         mult = mult.unsqueeze(0)\n",
    "        \n",
    "# #         print(mult.shape)\n",
    "        \n",
    "#         if concat_mult == None:\n",
    "#             concat_mult = mult\n",
    "#         else:\n",
    "# #             print(concat_mult.shape)\n",
    "#             concat_mult = torch.cat((concat_mult, mult), dim=0)\n",
    "        \n",
    "        \n",
    "#     print(concat_mult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 56, 56])\n",
      "ev torch.Size([32, 100, 3136])\n",
      "mean torch.Size([100, 3136])\n",
      "mean torch.Size([32, 100, 3136])\n",
      "diff: torch.Size([32, 100, 3136])\n",
      "diff: torch.Size([32, 3136, 100])\n",
      "diff_transpose: torch.Size([32, 100, 3136])\n",
      "0.9893512290000217\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "# mean, cov = getParameters(ev)\n",
    "calculateMeanAndCovarianceMatrix(ev)\n",
    "print(time.perf_counter()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0769770e+00, 1.0769770e+00, 1.0769770e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [3.4343752e-01, 4.9410871e-01, 4.1614291e-01, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.2526109e-02,\n",
       "        1.2526109e-02, 1.2526109e-02],\n",
       "       ...,\n",
       "       [6.4803241e-04, 6.4803241e-04, 6.4803241e-04, ..., 8.8993922e-02,\n",
       "        8.8993922e-02, 8.8993922e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [9.4800466e-01, 1.0566857e+00, 8.2606596e-01, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.0210126e-02,  1.0210126e-02,  1.0210126e-02, ...,\n",
       "          9.9999998e-03,  9.9999998e-03,  9.9999998e-03],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [-2.5765974e-06, -2.5765974e-06, -2.5765974e-06, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.9999998e-03,  9.9999998e-03,  9.9999998e-03, ...,\n",
       "          9.9999998e-03,  9.9999998e-03,  9.9999998e-03],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.9999998e-03,  9.9999998e-03,  9.9999998e-03, ...,\n",
       "          1.0201838e-02,  1.0201838e-02,  1.0201838e-02],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          1.2956212e-04,  1.2956212e-04,  1.2956212e-04],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.5765974e-06, -2.5765974e-06, -2.5765974e-06, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          1.2956212e-04,  1.2956212e-04,  1.2956212e-04],\n",
       "        ...,\n",
       "        [ 1.0006980e-02,  1.0006980e-02,  1.0006980e-02, ...,\n",
       "          1.0796458e-02,  1.0796458e-02,  1.0796458e-02],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.9999998e-03,  9.9999998e-03,  9.9999998e-03, ...,\n",
       "          9.9999998e-03,  9.9999998e-03,  9.9999998e-03],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.9999998e-03,  9.9999998e-03,  9.9999998e-03, ...,\n",
       "          9.9999998e-03,  9.9999998e-03,  9.9999998e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cov"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
